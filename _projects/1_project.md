---
layout: page
title: LMCache
description: Open-source KVCache backend for inference engines such as vLLM, SGLang
img: assets/img/lmcache.png
importance: 1
category: work
---

## About LMCache

LMCache is an open-source library designed to accelerate Large Language Model (LLM) inference, which supports KVCache offloading and multiple storage backends. It has been integrated into NVIDIA Dynamo in Sept. 2025

List of my PRs:

[LMCache](https://github.com/LMCache/LMCache/pulls/novahow)